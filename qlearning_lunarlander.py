# -*- coding: utf-8 -*-
"""QLearning_LunarLander.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZSigtcXUO3bZyGHYsoDmso8MiGFp_7IR
"""

!apt-get update -qq
!apt-get install -y build-essential
!apt-get install -y swig

!pip install gymnasium[box2d]

import gymnasium as gym
import numpy as np
import matplotlib.pyplot as plt

env = gym.make("LunarLander-v2")

alpha = 0.1  # Learning rate
gamma = 0.95  # Discount factor
epsilon = 0.2  # Exploration factor
num_episodes = 2000  # Number of episodes

Q_table = {}


def epsilon_greedy(state, epsilon):
    return env.action_space.sample() if np.random.random() < epsilon else get_best_action(state)


def get_best_action(state):
    q_values = Q_table.get(tuple(state), np.zeros(env.action_space.n))
    return np.argmax(q_values)


def q_learning_update(state, action, reward, next_state):
    q_current = Q_table.get(tuple(state), np.zeros(env.action_space.n))
    q_next = Q_table.get(tuple(next_state), np.zeros(env.action_space.n))
    q_current[action] += alpha * (reward + gamma * np.max(q_next) - q_current[action])
    Q_table[tuple(state)] = q_current


returns = []
try:
    for episode in range(num_episodes):
        state, info = env.reset()
        total_reward = 0
        done = False
        while not done:
            action = epsilon_greedy(state, epsilon)
            next_state, reward, done, truncated, info = env.step(action)
            q_learning_update(state, action, reward, next_state)
            state = next_state
            total_reward += reward
        returns.append(total_reward)
        if episode % 100 == 0:
            print(f"Episode {episode}, Total reward: {total_reward}")

    plt.figure(figsize=(14, 5))
    plt.plot(returns)
    plt.xlabel('Episode')
    plt.ylabel('Cumulative Reward')
    plt.title('Returns per Episode (Q-learning in Lunar Lander)')
    plt.show()
except Exception as e:
    print(f"An error occurred: {e}")
finally:
    env.close()


def simulate_learned_strategy(num_simulations=100):
    time_steps_to_goal = []
    try:
        for simulation in range(num_simulations):
            state, info = env.reset()
            time_step = 0
            done = False
            while not done:
                action = get_best_action(state)
                next_state, reward, done, truncated, info = env.step(action)
                state = next_state
                time_step += 1
            time_steps_to_goal.append(time_step)

        average_time_steps = np.mean(time_steps_to_goal)
        return average_time_steps
    except Exception as e:
        print(f"An error occurred during simulation: {e}")
    finally:
        env.close()


average_time_steps = simulate_learned_strategy(num_simulations=100)
print(f"Average time steps to achieve the goal using Q-learning in Lunar Lander: {average_time_steps}")

